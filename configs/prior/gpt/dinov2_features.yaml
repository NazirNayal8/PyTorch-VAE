MODEL:
  NAME: 'GPT'
  VOCAB_SIZE: 256  # size of codebook
  BLOCK_SIZE: 16   # num tokens representing a sample
  N_LAYER: 1
  N_HEAD: 8
  N_EMBD: 128 # hidden embedding size
  EMBD_PDROP: 0.0
  RESID_PDROP: 0.0
  ATTN_PDROP: 0.0
  N_UNMASKED: 0
  START_TOKEN_MODE: label
  NUM_CLASSES: 10

SOLVER:
  LR: 4.5e-6
  WEIGHT_DECAY: 0.0
  BATCH_SIZE: 256
  PRECISION: 32
  MAX_EPOCHS: 60
  NUM_WORKERS: 20

VQ_VAE: 
  CKPT_PATH: 'model_logs/dinov2_features/DINOV2Features/dinov2_features_256_128_reslayers-8_resdim-128_hiddendim256/last.ckpt'

DATA:
  ROOT: "/home/nazir/datasets"
  NAME: DINOV2Features
  SOURCE: CIFAR10
  NORMALIZATION: imagenet
  MEAN: [0.5, 0.5, 0.5]
  STD: [1.0, 1.0, 1.0]
  NUM_CLASSES: 10
  CLS_SUBSET: null

WANDB:
  ACTIVATE: True
  RUN_NAME: gpt_dinov2_features_256_128_reslayers-8_resdim-128_hiddendim256_nembed-128_1layer
  PROJECT: prior_pixel_cnn
  NUM_LOG_IMGS: 40
  LOG_DIR: logs/prior_gpt/
  GENERATE_SAMPLES: False

CKPT:
  DIR_PATH: model_logs/prior/gpt/
  EVERY_N_EPOCHS: 50

RANDOM_SEED: 2000

  